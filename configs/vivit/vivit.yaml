# Note  : *** the batch_size should be equal to the gpus number at the test phase!!! ***
data_cfg:
  dataset_name: CASIA-B
  dataset_root: ../Dataset/CASIA-B-pkl
  dataset_partition: ./datasets/CASIA-B/CASIA-B.json
  num_workers: 10
  remove_no_gallery: false
  test_dataset_name: CASIA-B

evaluator_cfg:
  enable_float16: false 
  restore_ckpt_strict: true
  restore_hint: 5000
  save_name: ViViT
  sampler:
    batch_size: 1
    sample_type: all_ordered
    type: InferenceSampler
    tub_depth : [4, 8, 16]

loss_cfg:
  - loss_term_weight: 1.0
    margin: 0.2
    type: TripletLoss
    log_prefix: triplet
  - loss_term_weight: 1.0
    scale: 1
    type: CrossEntropyLoss
    log_accuracy: true
    label_smooth: false
    log_prefix: softmax

model_cfg:
  model: ViViT
  channels: [1, 128]
  tub_depth : [4, 8, 16]
  patch_size : [4, 4, 8]
  kernel_size : [3, 5, 7, 9 ,11]
  class_num: 74

optimizer_cfg:
  lr: 1.0e-4
  solver: Adam
  weight_decay: 5.0e-4

scheduler_cfg:
  gamma: 0.1
  milestones:
    - 70000
  scheduler: MultiStepLR

trainer_cfg:
  enable_float16: true
  with_test: true
  log_iter: 100
  restore_ckpt_strict: true
  restore_hint: 0
  save_iter: 5000
  save_name: ViViT
  sync_BN: true
  total_iter: 80000
  sampler:
    tub_depth : [4, 8, 16]
    batch_shuffle: true
    batch_size:
      - 4
      - 6
    frames_num_fixed: 32
    frames_skip_num: 0
    sample_type: fixed_ordered
    type: TripletSampler
